{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kbDr21sVsJ8p"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # for plotting beautiful graphs\n",
        "\n",
        "# train test split from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import Torch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "# from torch.utils.data import SubsetRandomSampler\n",
        "from torch.autograd import Variable\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# What's in the current directory?\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\", dtype=np.float32)\n",
        "final_test = pd.read_csv(\"test.csv\", dtype=np.float32)\n"
      ],
      "metadata": {
        "id": "n2NkWoQcsSx5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate the features and labels\n",
        "targets_np = train.label.values\n",
        "features_np = train.loc[:, train.columns != 'label'].values/255\n",
        "\n",
        "# Split into training and test set\n",
        "features_train, features_test, target_train, target_test = train_test_split(features_np, targets_np, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "LQr6izcTsbzk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
        "featuresTrain = torch.from_numpy(features_train)\n",
        "targetsTrain = torch.from_numpy(target_train).type(torch.LongTensor) # data type is long\n",
        "\n",
        "# create feature and targets tensor for test set.\n",
        "featuresTest = torch.from_numpy(features_test)\n",
        "targetsTest = torch.from_numpy(target_test).type(torch.LongTensor) # data type is long"
      ],
      "metadata": {
        "id": "hRiBUrAtv5Zl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch size\n",
        "batch_size = 256\n",
        "\n",
        "# Pytorch train and test sets\n",
        "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
        "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "gbGfV7O1wKPb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 5 Hidden Layer Network\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)\n",
        "        \n",
        "        # Dropout module with 0.2 probbability\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        # Add softmax on output layer\n",
        "        self.log_softmax = F.log_softmax\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = self.dropout(F.relu(self.fc4(x)))\n",
        "        \n",
        "        x = self.log_softmax(self.fc5(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "hJRlxkrmwet3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate our model\n",
        "model = Classifier()\n",
        "# Define our loss function\n",
        "criterion = nn.NLLLoss()\n",
        "# Define the optimier\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0015)\n",
        "\n",
        "epochs = 25\n",
        "steps = 0\n",
        "print_every = 50\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        steps += 1\n",
        "        # Prevent accumulation of gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Make predictions\n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        #backprop\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "\n",
        "            # Turn off gradients for validation\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                for images, labels in test_loader:\n",
        "                    log_ps = model(images)\n",
        "                    test_loss += criterion(log_ps, labels)\n",
        "\n",
        "                    ps = torch.exp(log_ps)\n",
        "                    # Get our top predictions\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            train_losses.append(running_loss/len(train_loader))\n",
        "            test_losses.append(test_loss/len(test_loader))\n",
        "\n",
        "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                  \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
        "                  \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
        "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M69xgUbDw8uM",
        "outputId": "91f11b61-e935-4b39-981e-8291a466657b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/25..  Training Loss: 0.420..  Test Loss: 0.421..  Test Accuracy: 0.880\n",
            "Epoch: 1/25..  Training Loss: 0.575..  Test Loss: 0.279..  Test Accuracy: 0.916\n",
            "Epoch: 2/25..  Training Loss: 0.037..  Test Loss: 0.215..  Test Accuracy: 0.935\n",
            "Epoch: 2/25..  Training Loss: 0.121..  Test Loss: 0.185..  Test Accuracy: 0.944\n",
            "Epoch: 2/25..  Training Loss: 0.196..  Test Loss: 0.147..  Test Accuracy: 0.957\n",
            "Epoch: 3/25..  Training Loss: 0.041..  Test Loss: 0.143..  Test Accuracy: 0.958\n",
            "Epoch: 3/25..  Training Loss: 0.096..  Test Loss: 0.130..  Test Accuracy: 0.960\n",
            "Epoch: 4/25..  Training Loss: 0.003..  Test Loss: 0.130..  Test Accuracy: 0.962\n",
            "Epoch: 4/25..  Training Loss: 0.044..  Test Loss: 0.115..  Test Accuracy: 0.967\n",
            "Epoch: 4/25..  Training Loss: 0.087..  Test Loss: 0.115..  Test Accuracy: 0.965\n",
            "Epoch: 5/25..  Training Loss: 0.016..  Test Loss: 0.116..  Test Accuracy: 0.966\n",
            "Epoch: 5/25..  Training Loss: 0.052..  Test Loss: 0.126..  Test Accuracy: 0.964\n",
            "Epoch: 5/25..  Training Loss: 0.089..  Test Loss: 0.102..  Test Accuracy: 0.971\n",
            "Epoch: 6/25..  Training Loss: 0.026..  Test Loss: 0.098..  Test Accuracy: 0.972\n",
            "Epoch: 6/25..  Training Loss: 0.057..  Test Loss: 0.108..  Test Accuracy: 0.969\n",
            "Epoch: 7/25..  Training Loss: 0.004..  Test Loss: 0.101..  Test Accuracy: 0.971\n",
            "Epoch: 7/25..  Training Loss: 0.027..  Test Loss: 0.108..  Test Accuracy: 0.971\n",
            "Epoch: 7/25..  Training Loss: 0.057..  Test Loss: 0.109..  Test Accuracy: 0.971\n",
            "Epoch: 8/25..  Training Loss: 0.011..  Test Loss: 0.112..  Test Accuracy: 0.971\n",
            "Epoch: 8/25..  Training Loss: 0.032..  Test Loss: 0.096..  Test Accuracy: 0.974\n",
            "Epoch: 8/25..  Training Loss: 0.055..  Test Loss: 0.097..  Test Accuracy: 0.972\n",
            "Epoch: 9/25..  Training Loss: 0.018..  Test Loss: 0.104..  Test Accuracy: 0.973\n",
            "Epoch: 9/25..  Training Loss: 0.036..  Test Loss: 0.103..  Test Accuracy: 0.972\n",
            "Epoch: 10/25..  Training Loss: 0.004..  Test Loss: 0.095..  Test Accuracy: 0.974\n",
            "Epoch: 10/25..  Training Loss: 0.019..  Test Loss: 0.101..  Test Accuracy: 0.973\n",
            "Epoch: 10/25..  Training Loss: 0.037..  Test Loss: 0.093..  Test Accuracy: 0.977\n",
            "Epoch: 11/25..  Training Loss: 0.010..  Test Loss: 0.110..  Test Accuracy: 0.972\n",
            "Epoch: 11/25..  Training Loss: 0.028..  Test Loss: 0.102..  Test Accuracy: 0.973\n",
            "Epoch: 11/25..  Training Loss: 0.045..  Test Loss: 0.115..  Test Accuracy: 0.971\n",
            "Epoch: 12/25..  Training Loss: 0.015..  Test Loss: 0.091..  Test Accuracy: 0.976\n",
            "Epoch: 12/25..  Training Loss: 0.032..  Test Loss: 0.099..  Test Accuracy: 0.975\n",
            "Epoch: 13/25..  Training Loss: 0.006..  Test Loss: 0.104..  Test Accuracy: 0.973\n",
            "Epoch: 13/25..  Training Loss: 0.021..  Test Loss: 0.095..  Test Accuracy: 0.976\n",
            "Epoch: 13/25..  Training Loss: 0.033..  Test Loss: 0.106..  Test Accuracy: 0.976\n",
            "Epoch: 14/25..  Training Loss: 0.008..  Test Loss: 0.101..  Test Accuracy: 0.977\n",
            "Epoch: 14/25..  Training Loss: 0.019..  Test Loss: 0.092..  Test Accuracy: 0.977\n",
            "Epoch: 15/25..  Training Loss: 0.000..  Test Loss: 0.099..  Test Accuracy: 0.977\n",
            "Epoch: 15/25..  Training Loss: 0.010..  Test Loss: 0.110..  Test Accuracy: 0.975\n",
            "Epoch: 15/25..  Training Loss: 0.022..  Test Loss: 0.093..  Test Accuracy: 0.978\n",
            "Epoch: 16/25..  Training Loss: 0.004..  Test Loss: 0.097..  Test Accuracy: 0.978\n",
            "Epoch: 16/25..  Training Loss: 0.013..  Test Loss: 0.116..  Test Accuracy: 0.974\n",
            "Epoch: 16/25..  Training Loss: 0.025..  Test Loss: 0.100..  Test Accuracy: 0.977\n",
            "Epoch: 17/25..  Training Loss: 0.008..  Test Loss: 0.116..  Test Accuracy: 0.975\n",
            "Epoch: 17/25..  Training Loss: 0.019..  Test Loss: 0.103..  Test Accuracy: 0.978\n",
            "Epoch: 18/25..  Training Loss: 0.001..  Test Loss: 0.107..  Test Accuracy: 0.975\n",
            "Epoch: 18/25..  Training Loss: 0.009..  Test Loss: 0.097..  Test Accuracy: 0.979\n",
            "Epoch: 18/25..  Training Loss: 0.019..  Test Loss: 0.105..  Test Accuracy: 0.978\n",
            "Epoch: 19/25..  Training Loss: 0.004..  Test Loss: 0.093..  Test Accuracy: 0.979\n",
            "Epoch: 19/25..  Training Loss: 0.012..  Test Loss: 0.113..  Test Accuracy: 0.976\n",
            "Epoch: 19/25..  Training Loss: 0.023..  Test Loss: 0.095..  Test Accuracy: 0.977\n",
            "Epoch: 20/25..  Training Loss: 0.006..  Test Loss: 0.113..  Test Accuracy: 0.975\n",
            "Epoch: 20/25..  Training Loss: 0.013..  Test Loss: 0.107..  Test Accuracy: 0.977\n",
            "Epoch: 21/25..  Training Loss: 0.002..  Test Loss: 0.108..  Test Accuracy: 0.976\n",
            "Epoch: 21/25..  Training Loss: 0.012..  Test Loss: 0.106..  Test Accuracy: 0.977\n",
            "Epoch: 21/25..  Training Loss: 0.021..  Test Loss: 0.105..  Test Accuracy: 0.977\n",
            "Epoch: 22/25..  Training Loss: 0.004..  Test Loss: 0.119..  Test Accuracy: 0.977\n",
            "Epoch: 22/25..  Training Loss: 0.011..  Test Loss: 0.108..  Test Accuracy: 0.977\n",
            "Epoch: 22/25..  Training Loss: 0.019..  Test Loss: 0.109..  Test Accuracy: 0.978\n",
            "Epoch: 23/25..  Training Loss: 0.008..  Test Loss: 0.108..  Test Accuracy: 0.978\n",
            "Epoch: 23/25..  Training Loss: 0.014..  Test Loss: 0.122..  Test Accuracy: 0.977\n",
            "Epoch: 24/25..  Training Loss: 0.003..  Test Loss: 0.110..  Test Accuracy: 0.978\n",
            "Epoch: 24/25..  Training Loss: 0.012..  Test Loss: 0.106..  Test Accuracy: 0.977\n",
            "Epoch: 24/25..  Training Loss: 0.021..  Test Loss: 0.106..  Test Accuracy: 0.978\n",
            "Epoch: 25/25..  Training Loss: 0.003..  Test Loss: 0.118..  Test Accuracy: 0.976\n",
            "Epoch: 25/25..  Training Loss: 0.010..  Test Loss: 0.103..  Test Accuracy: 0.978\n",
            "Epoch: 25/25..  Training Loss: 0.018..  Test Loss: 0.113..  Test Accuracy: 0.977\n"
          ]
        }
      ]
    }
  ]
}